{% set name = "ollama" %}
{% set goname = "github.com/jmorganca/ollama" %}
{% set version = "0.1.11" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  #url: https://{{ goname }}/archive/v{{ version }}.tar.gz
  #sha256: 881d81d6a113f5361fc1648ee3f07f596b96a25ff9c9e6b243c2386adb8a0b26
  git_url: https://github.com/jmorganca/ollama.git
  git_rev: v{{ version }}

build:
  number: 2
  skip: True  # [not linux]
  string: cuda{{ cuda_compiler_version | replace('.', '') }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != "None"]
  script:
    - export GOFLAGS="'-ldflags=-X=github.com/jmorganca/ollama/version.Version={{ version }} -X=github.com/jmorganca/ollama/server.mode=release'"
    - go generate ./...
    - go install .
    - go-licenses save --save_path licenses ./...

requirements:
  build:
    - cmake
    - make
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}  # [cuda_compiler_version not in (undefined, "None")]
    - {{ compiler('go') }} 1.20
    - go-licenses
  host:
    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version not in (undefined, "None")]
  run:
    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version not in (undefined, "None")]

test:
  commands:
    - ollama --version
    - ollama --help

about:
  home: https://ollama.ai
  summary: Get up and running with Llama 2 and other large language models locally
  license: MIT
  license_family: MIT
  license_file:
    - LICENSE
    - licenses/
  dev_url: https://{{ goname }}

extra:
  recipe-maintainers:
    - sodre
